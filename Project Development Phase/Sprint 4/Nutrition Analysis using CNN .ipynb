{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0f8d565",
   "metadata": {},
   "source": [
    "# Nutrition Image Analysis using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6586936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71de16db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "cos_client = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='FZh6KoHYIYEl01qnNm1TSKfsvBKvrMOqGfFji9MwrBFY',\n",
    "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n",
    "\n",
    "bucket = 'nutritionimageanalysisusingcnn-donotdelete-pr-8jvxt2g27j8ewb'\n",
    "object_key = 'DATA_SET.zip'\n",
    "\n",
    "streaming_body_1 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n",
    "\n",
    "# Your data file was loaded into a botocore.response.StreamingBody object.\n",
    "# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n",
    "# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n",
    "# pandas documentation: http://pandas.pydata.org/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961f1646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import zipfile\n",
    "\n",
    "zip_ref = zipfile.ZipFile(BytesIO(streaming_body_1.read()), 'r')\n",
    "filepath=zip_ref.namelist()\n",
    "for path in filepath:\n",
    "    zip_ref.extract(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14015c2",
   "metadata": {},
   "source": [
    "### Importing Neccessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ce19f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np#used for numerical analysis\n",
    "import tensorflow #open source used for both ML and DL for computation\n",
    "from tensorflow.keras.models import Sequential #it is a plain stack of layers\n",
    "from tensorflow.keras import layers #A layer consists of a tensor-in tensor-out computation function\n",
    "#Dense layer is the regular deeply connected neural network layer\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "#Faltten-used fot flattening the input or change the dimension\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dropout #Convolutional layer\n",
    "#MaxPooling2D-for downsampling the image\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5ba9c2",
   "metadata": {},
   "source": [
    "### Image Data Agumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e890c8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting parameter for Image Data agumentation to the training data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "#Image Data agumentation to the testing data\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0efd5bb",
   "metadata": {},
   "source": [
    "### Loading our data and performing data agumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d90a6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing data agumentation to train data\n",
    "x_train = train_datagen.flow_from_directory(\n",
    "    \"/home/wsuser/work/TRAIN_SET\",\n",
    "    target_size=(64, 64),batch_size=5,color_mode='rgb',class_mode='sparse')\n",
    "#performing data agumentation to test data\n",
    "x_test = test_datagen.flow_from_directory(\n",
    "    \"/home/wsuser/work/TEST_SET\",\n",
    "    target_size=(64, 64),batch_size=5,color_mode='rgb',class_mode='sparse') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86483ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.class_indices)#checking the number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daad3700",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test.class_indices)#checking the number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2fa286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter as c\n",
    "c(x_train .labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a1adbb",
   "metadata": {},
   "source": [
    "### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a447286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# First convolution layer and pooling\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second convolution layer and pooling\n",
    "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "# input_shape is going to be the pooled feature maps from the previous convolution layer\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening the layers\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Adding a fully connected layer\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(Dense(units=5, activation='softmax')) # softmax for more than 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21206cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.summary()#summary of our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f6d9ee",
   "metadata": {},
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0921085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the CNN\n",
    "# categorical_crossentropy for more than 2\n",
    "classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9c4b59",
   "metadata": {},
   "source": [
    "## Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59c3c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit_generator(\n",
    "        generator=x_train,steps_per_epoch = len(x_train),\n",
    "        epochs=20, validation_data=x_test,validation_steps = len(x_test))# No of images in test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6020076",
   "metadata": {},
   "source": [
    "### Saving our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c81ccee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "classifier.save('nutrition.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422c8c5b",
   "metadata": {},
   "source": [
    "### Predicting our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7edc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "model = load_model(\"nutrition.h5\") #loading the model for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a67f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @hidden_cell\n",
    "# The following code contains the credentials for a file in your IBM Cloud Object Storage.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "metadata_1 = {\n",
    "    'IAM_SERVICE_ID': 'iam-ServiceId-74189603-8871-47a9-b3c3-a11ff4a1a970',\n",
    "    'IBM_API_KEY_ID': 'FZh6KoHYIYEl01qnNm1TSKfsvBKvrMOqGfFji9MwrBFY',\n",
    "    'ENDPOINT': 'https://s3.private.us.cloud-object-storage.appdomain.cloud',\n",
    "    'IBM_AUTH_ENDPOINT': 'https://iam.cloud.ibm.com/oidc/token',\n",
    "    'BUCKET': 'nutritionimageanalysisusingcnn-donotdelete-pr-8jvxt2g27j8ewb',\n",
    "    'FILE': 'Test.jpg'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4b6fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(\"metadata_1\",\n",
    "                     grayscale=False,target_size= (64,64))#loading of the image\n",
    "x = image.img_to_array(img)#image to array\n",
    "x = np.expand_dims(x,axis = 0)#changing the shape\n",
    "pred = model.predict_classes(x)#predicting the classes\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a0c8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "index=['APPLES', 'BANANA', 'ORANGE','PINEAPPLE','WATERMELON']\n",
    "result=str(index[pred[0]])\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
